---
title: "Assignment 2"
author: "Marissa Hausman"
date: "August 16, 2016"
output: pdf_document
---

## I. Flights at ABIA

#### 1. Overview

Create a figure, or set of related figures, that tell an interesting story about flights into and out of Austin. What is the best time to fly to minimize delays?

#### 2. Data and Model

In order to address this question, the Month, DayOfWeek, DepTime, ArrDelay, and DepDelay columns of the dataset, ABIA, will be used. First plot ArrDelay and DepDelay by Month to find the Month with the shortest delays. Next subset the data to only that Month and find the DayOfWeek with the shortest delays. Next subset the data to only that DayOfWeek of that Month and find the group of DepTime with the shortest delays. The results of this analysis provide the time to fly that has been, in the past, the time to fly with the shortest delays. This is the optimal time to fly to minimize delays.

#### 3. Results

```{r include=FALSE}
abia = read.csv('C:/Users/maris/OneDrive/Summer 2016/Predictive Modeling PART 2/Assignment 2/ABIA.csv', header=TRUE)
```

**September has the shortest delays, on average:**

```{r, echo=FALSE}
plot(abia$Month, abia$ArrDelay/60, pch=19, col=ifelse(abia$Month==9,'yellow','blue'), xlab='Month', ylab='ArrDelay (in hours)', main='ArrDelays by Month')
plot(abia$Month, abia$DepDelay/60, pch=19, col=ifelse(abia$Month==9,'yellow','blue'), xlab='Month', ylab='DepDelay (in hours)', main='DepDelays by Month')
```

```{r include=FALSE}
sept=abia[which(abia$Month==9),]
```

**Fridays in September have the shortest delays, on average:**

```{r, echo=FALSE}
plot(sept$DayOfWeek, sept$ArrDelay/60, pch=19, col=ifelse(sept$DayOfWeek==6,'yellow','blue'), xlab='Day of Week', ylab='ArrDelay (in hours)', main='September ArrDelays by Day of Week')
plot(sept$DayOfWeek, sept$DepDelay/60, pch=19, col=ifelse(sept$DayOfWeek==6,'yellow','blue'), xlab='Day of Week', ylab='DepDelay (in hours)', main='September DepDelays by Day of Week')
```

```{r include=FALSE}
septfriday=sept[which(sept$DayOfWeek==6),]
```

**Departure times in the early morning and late at night on Fridays in September have the shortest delays, on average:**

```{r, echo=FALSE}
plot(septfriday$DepTime, septfriday$ArrDelay/60, pch=19, col=ifelse(septfriday$DepTime>=2000|septfriday$DepTime<940,'yellow','blue'), xlab='Departure Time', ylab='ArrDelay (in hours)', main='September Fridays ArrDelays by Departure Time')
plot(septfriday$DepTime, septfriday$DepDelay/60, pch=19, col=ifelse(septfriday$DepTime>=2200|septfriday$DepTime<700,'yellow','blue'), xlab='Departure Time', ylab='DepDelay (in hours)', main='September Fridays DepDelays by Departure Time')
```

#### 4. Conclusion

The best Month to fly to minimize delays is September. The best DayOfWeek to fly in September is Friday. The best DepTime to fly on Fridays in September is very early in the morning or very late at night.


## II. Author Attribution

#### I. Overview

Revisit the Reuters C50 corpus that we explored in class. Your task is to build two separate models (using any combination of tools you see fit) for predicting the author of an article on the basis of that article's textual content. Describe clearly what models you are using, how you constructed features, and so forth. (Yes, this is a supervised learning task, but it potentially draws on a lot of what you know about unsupervised learning!)

In the C50train directory, you have ~50 articles from each of 50 different authors (one author per directory). Use this training data (and this data alone) to build the two models. Then apply your model to the articles by the same authors in the C50test directory, which is about the same size as the training set. How well do your models do at predicting the author identities in this out-of-sample setting? Are there any sets of authors whose articles seem difficult to distinguish from one another? Which model do you prefer?

#### 2. Data and Model

Naive Bayes will be used to detect the authors of articles based on those articles' textual content. A document term matrix will be created for both the training and test sets and the log probabilities will be compared. For each test document, the author corresponding to the largest log probability is that document's predicted author. The accuracy of these results will be tested using a confusion matrix.

#### 3. Results

```{r include=FALSE}
library(tm)
library(foreach)

# Reader wrapper function
readerPlain = function(fname){
  readPlain(elem = list(content = readLines(fname)), 
            id =  fname, language = 'en') }

# Rolling directories together
author_dirs = Sys.glob('C:/Users/maris/OneDrive/Summer 2016/Predictive Modeling PART 2/Assignment 2/ReutersC50/C50train/*')
file_list = NULL
labels = NULL
for(author in author_dirs) {
  author_name = substring(author, first = 97)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  labels = append(labels, rep(author_name, length(files_to_add)))
}

# Need a more clever regex to get better names here
all_docs = lapply(file_list, readerPlain) 
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))

# Training corpus
my_corpus = Corpus(VectorSource(all_docs))
names(my_corpus) = file_list

# Preprocessing
my_corpus = tm_map(my_corpus, content_transformer(tolower)) # make everything lowercase
my_corpus = tm_map(my_corpus, content_transformer(removeNumbers)) # remove numbers
my_corpus = tm_map(my_corpus, content_transformer(removePunctuation)) # remove punctuation
my_corpus = tm_map(my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
my_corpus = tm_map(my_corpus, content_transformer(removeWords), stopwords("SMART"))

# Document term matrix
DTM = DocumentTermMatrix(my_corpus)
DTM # some basic summary statistics

# Remove sparse items
DTM = removeSparseTerms(DTM, 0.975)
DTM

# Now a dense matrix
X = as.matrix(DTM)
smooth_count = 1/nrow(X)

# Naive Bayes: the training sets for all the authors
w = list()
smooth_count = 1/nrow(X)
j = 1
for (i in seq(1,length(file_list),50) )
{
  w[[j]] = colSums(X[i:(i+49),] + smooth_count)/sum(colSums(X[i:(i+49),] 
                                                            + smooth_count))
  j = j + 1
}


###################################################

# Same for the test set

readerPlain = function(fname){
  readPlain(elem = list(content = readLines(fname)), 
            id = fname, language = 'en') }

# Rolling directories together
author_dirs_test = Sys.glob('C:/Users/maris/OneDrive/Summer 2016/Predictive Modeling PART 2/Assignment 2/ReutersC50/C50test/*')
file_list_test = NULL
labels_test = NULL
for(author in author_dirs_test) {
  author_name = substring(author, first = 96)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list_test = append(file_list_test, files_to_add)
  labels_test = append(labels_test, rep(author_name, length(files_to_add)))
}

# Need a more clever regex to get better names here
all_docs_test = lapply(file_list_test, readerPlain) 
names(all_docs_test) = file_list_test
names(all_docs_test) = sub('.txt', '', names(all_docs_test))

# Test corpus
my_corpus_test = Corpus(VectorSource(all_docs_test))
names(my_corpus_test) = labels_test

# Preprocessing
my_corpus_test = tm_map(my_corpus_test, content_transformer(tolower)) # make everything lowercase
my_corpus_test = tm_map(my_corpus_test, content_transformer(removeNumbers)) # remove numbers
my_corpus_test = tm_map(my_corpus_test, content_transformer(removePunctuation)) # remove punctuation
my_corpus_test = tm_map(my_corpus_test, content_transformer(stripWhitespace)) ## remove excess white-space
my_corpus_test = tm_map(my_corpus_test, content_transformer(removeWords), stopwords("SMART"))

# Document term matrix
DTM_test = DocumentTermMatrix(my_corpus_test)
DTM_test # some basic summary statistics

# Keep only the words from the training set
common_words = colnames(DTM_test)[colnames(DTM_test) %in% colnames(DTM)]
DTM_test = DTM_test[, common_words]
DTM_test

# Compare log probabilities 
X_test = as.matrix(DTM_test)

# Empty matrix to calculate log probabilities
Y_test = matrix(, nrow = 2500, ncol = 50)
j = 1
for (i in 1:2500) {
  for (j in 1:50) {
    Y_test[i,j] = sum(X_test[i,]*log(w[[j]]))
  }
}

###################################################

# Find author that corresponds to the max log probability

library(dplyr)
author_pred = as.vector(t(as.data.frame(t(Y_test)) %>% summarise_each(funs(which.max(.)))))
author_actual = as.vector(rep(1:50,each=50))

# Confusion matrix
library(caret)
library(e1071)
confMatrix = confusionMatrix(author_pred,author_actual)
confMatrix$overall["Accuracy"]
```

```{r echo=FALSE}
confMatrix
```

**Classes with low (<0.4) sensitivity (pos pred value):** 4, 7, 8, 9, 13, 15, 35, 44, 50

#### 4. Conclusion

Overall, **Naive Bayes is 60.36% accurate** in determining the author identities in this out-of-sample setting. Authors whose articles seem difficult to identify are: Benjamin Kang Lim, Darren Schuettler, David Lawder, Edna Fernandes, Heather Scoffield, Jan Lopatka, Mure Dickie, Scott Hillis, and William Kazer.


## III. Practice with Association Rule Mining

#### 1. Overview

Use the data on grocery purchases in groceries.txt and find some interesting association rules for these shopping baskets. The data file is a list of baskets: one row per basket, with multiple items per row separated by commas -- you'll have to cobble together a few utilities for processing this into the format expected by the "arules" package. Pick your own thresholds for lift and confidence; just be clear what these thresholds are and how you picked them. Do your discovered item sets make sense? Present your discoveries in an interesting and concise way.

#### 2. Data and Model

The following table shows the top 20 items in the groceries.txt dataset:

```{r include=FALSE}
library(arules)
library(arulesViz)

groceries = read.transactions(file="C:/Users/maris/OneDrive/Summer 2016/Predictive Modeling PART 2/Assignment 2/groceries.txt", rm.duplicates=TRUE, format="basket", sep=',')
```

```{r echo=FALSE}
itemFrequencyPlot(groceries,topN=20,type="absolute",col='blue',xlab='Item',main='Frequency of Item Purchases')
```

The 'arules' package will be used to perform a market basket analysis on the groceries.txt dataset. The thresholds for support, confidence, and lift will be determined based on the number of rules generated by different combinations.

#### 3. Results

**With support=.01 and confidence=.3, there are 125 rules:**

```{r include=FALSE}
rules = apriori(groceries, parameter = list(support=.01, confidence=.3, target='rules'))
```

```{r echo=FALSE}
plot(rules)
```

**Choice of Thresholds:**

* Support=.01. The percent of transactions with the item set is at least 1%. Items must meet this minimum sales threshold.
* Confidence=.3. Item Y must appear in baskets that contain X at least 30% of the time.
* Lift=2.3. A lift of 2.3 provides 21 remaining rules to work with. For each of these rules, people are 2.3 times more likely to have item Y in their basket than random.

**The following are the 21 association rules:**

```{r echo=FALSE}
inspect(subset(rules, subset=lift > 2.3))
```

#### 4. Conclusion

From the results, it is apparent that other vegetables, root vegetables, and yogurt are the items most likely to be purchased based on various item sets. All three of those items fall in the top 20 most frequently purchased items (other vegetables ranks #2, yogurt ranks #5, and root vegetables ranks #7). The discovered item sets make sense: in looking at specific item sets, it is apparent that people who buy other dairy products (whipped/sour cream, whole milk) are likely to buy yogurt, people who buy other produce (other vegetables, tropical fruit) are likely to buy root vegetables, and people who buy specific vegetables (onions, root vegetables) are likely to buy other vegetables.
